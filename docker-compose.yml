version: '3.8'  
  
services:  
  bv_service:  
    image: wf_service:v0.0.2
    runtime: nvidia  
    shm_size: 32G  
    deploy:  
      resources:  
        reservations:  
          devices:  
            - capabilities: [gpu]  
    devices:  
      - /dev/nvidia-uvm:/dev/nvidia-uvm  
      - /dev/nvidia-uvm-tools:/dev/nvidia-uvm-tools  
      - /dev/nvidiactl:/dev/nvidiactl  
      - /dev/nvidia0:/dev/nvidia0  
    ports:  
      - "52011:80"  
    volumes:  
      - /userdata/bobo/whisper_finetune_train:/mnt2  
      - /userdata/bobo/whisper_finetune_service:/mnt  
      - /userdata/bobo/whisper_finetune_service/tmp:/tmp  
    stdin_open: true  
    tty: true  


# docker-compose up -d  
# docker run -d -it --gpus all --shm-size 32G --runtime nvidia --device=/dev/nvidia-uvm --device=/dev/nvidia-uvm-tools --device=/dev/nvidiactl --device=/dev/nvidia0 --name wf_service -p 52011:80 -v /userdata/bobo/whisper_finetune_train:/mnt2 -v /userdata/bobo/whisper_finetune_service:/mnt -v /userdata/bobo/whisper_finetune_service/tmp:/tmp wf_service:v0.0.1 bash
